{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Regression with Neural Networks in TensorFlow\n",
    "\n",
    "Simple definition : predicting a numerical variable based on some other combination of variables, even shorter... predicting a number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.18.0\n"
     ]
    }
   ],
   "source": [
    "# Import TensorFlow\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating data to view and fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create features\n",
    "X = np.array([-7.0, -4.0, -1.0, 2.0, 5.0, 8.0, 11.0, 14.0])\n",
    "\n",
    "# Create labels\n",
    "y = np.array([3.0, 6.0, 9.0, 12.0, 15.0, 18.0, 21.0, 24.0])\n",
    "\n",
    "# Visualize it\n",
    "plt.scatter(X, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y == X + 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input and output shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'bedroom', b'bathroom', b'garage'], dtype=object)>,\n",
       " <tf.Tensor: shape=(1,), dtype=int32, numpy=array([939700])>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a demo tensor for our housing price prediction problem\n",
    "house_info = tf.constant([\"bedroom\", \"bathroom\", \"garage\"])\n",
    "house_price = tf.constant([939700])\n",
    "house_info, house_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-7.0, 3.0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0], y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-4.0, 6.0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1], y[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((), ())"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = X[0].shape\n",
    "output_shape = y[0].shape\n",
    "input_shape, output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-7.0, 3.0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0], y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn our NumPy arrays into tensors with dtype float32\n",
    "X = tf.cast(tf.constant(X), dtype=tf.float32)\n",
    "y = tf.cast(tf.constant(y), dtype=tf.float32)\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([]), TensorShape([]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = X[0].shape\n",
    "output_shape = y[0].shape\n",
    "input_shape, output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x29dcd747b20>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps in modelling with TensorFlow\n",
    "\n",
    "1. **Creating a model** - define the input and output layers, as well as the hidden layers of a deep learning model.\n",
    "2. **Compiling a model** - define the loss funtion (in other words, the function which tells our model how wrong it is) and the optimizer (tells our model how to improve the patterns its learning) and evaluation metrics (what we can use to interpret the performance of our model).\n",
    "3. Fitting a model - letting the model try to find patterns between X & y (features and labels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422ms/step - loss: 8.0376 - mae: 8.0376\n",
      "Epoch 2/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 7.9051 - mae: 7.9051\n",
      "Epoch 3/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 7.7726 - mae: 7.7726\n",
      "Epoch 4/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 7.6401 - mae: 7.6401\n",
      "Epoch 5/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 7.5076 - mae: 7.5076\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x29dcf6f7f70>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model using the Sequential API\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=tf.keras.losses.mae, # mae is short for mean absolute error\n",
    "              optimizer=tf.keras.optimizers.SGD(), # sgd is short for stochasitc gradient descent\n",
    "              metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "# model.fit(X, y, epochs=5)\n",
    "model.fit(tf.expand_dims(X, axis=-1), y, epochs=5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out X and y\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[29.556707]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try and make a prediction using our model\n",
    "y_pred = model.predict(np.array([17.0]))\n",
    "# y_pred = model.predict([17.0])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving our model\n",
    "\n",
    "We can improve our model, by altering the steps we took to create a model.\n",
    "\n",
    "1. **Creating a model** - here we might add more layers, increase the number of hidden units (all called neurons) within each of the hideen layers, change the activation function of each layer.\n",
    "2. **Compiling a model** - here we might change the optimization function or perhaps the **learning rate** of the optimization function.\n",
    "3. **Fitting a model** - here we might fit a model for more **epochs** (leave it training for longer) or on more data (give the model more examples to learn from)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 579ms/step - loss: 8.2804 - mae: 8.2804\n",
      "Epoch 2/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 8.1479 - mae: 8.1479\n",
      "Epoch 3/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 8.0154 - mae: 8.0154\n",
      "Epoch 4/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 7.8829 - mae: 7.8829\n",
      "Epoch 5/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 7.7504 - mae: 7.7504\n",
      "Epoch 6/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 7.6179 - mae: 7.6179\n",
      "Epoch 7/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 7.4854 - mae: 7.4854\n",
      "Epoch 8/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 7.4475 - mae: 7.4475\n",
      "Epoch 9/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 7.4419 - mae: 7.4419\n",
      "Epoch 10/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 7.4362 - mae: 7.4362\n",
      "Epoch 11/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 7.4306 - mae: 7.4306\n",
      "Epoch 12/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 7.4250 - mae: 7.4250\n",
      "Epoch 13/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 7.4194 - mae: 7.4194\n",
      "Epoch 14/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 7.4138 - mae: 7.4138\n",
      "Epoch 15/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 7.4081 - mae: 7.4081\n",
      "Epoch 16/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 7.4025 - mae: 7.4025\n",
      "Epoch 17/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 7.3969 - mae: 7.3969\n",
      "Epoch 18/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 7.3913 - mae: 7.3913\n",
      "Epoch 19/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 7.3856 - mae: 7.3856\n",
      "Epoch 20/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 7.3800 - mae: 7.3800\n",
      "Epoch 21/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 7.3744 - mae: 7.3744\n",
      "Epoch 22/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 7.3687 - mae: 7.3687\n",
      "Epoch 23/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 7.3631 - mae: 7.3631\n",
      "Epoch 24/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 7.3575 - mae: 7.3575\n",
      "Epoch 25/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 7.3519 - mae: 7.3519\n",
      "Epoch 26/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 7.3463 - mae: 7.3463\n",
      "Epoch 27/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 7.3406 - mae: 7.3406\n",
      "Epoch 28/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 7.3350 - mae: 7.3350\n",
      "Epoch 29/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 7.3294 - mae: 7.3294\n",
      "Epoch 30/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 7.3238 - mae: 7.3238\n",
      "Epoch 31/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 7.3181 - mae: 7.3181\n",
      "Epoch 32/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 7.3125 - mae: 7.3125\n",
      "Epoch 33/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 7.3069 - mae: 7.3069\n",
      "Epoch 34/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 7.3013 - mae: 7.3013\n",
      "Epoch 35/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 7.2956 - mae: 7.2956\n",
      "Epoch 36/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 7.2900 - mae: 7.2900\n",
      "Epoch 37/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 7.2844 - mae: 7.2844\n",
      "Epoch 38/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 7.2788 - mae: 7.2788\n",
      "Epoch 39/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 7.2731 - mae: 7.2731\n",
      "Epoch 40/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 7.2675 - mae: 7.2675\n",
      "Epoch 41/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 7.2619 - mae: 7.2619\n",
      "Epoch 42/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 7.2562 - mae: 7.2562\n",
      "Epoch 43/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 7.2506 - mae: 7.2506\n",
      "Epoch 44/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 7.2450 - mae: 7.2450\n",
      "Epoch 45/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 7.2394 - mae: 7.2394\n",
      "Epoch 46/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 7.2338 - mae: 7.2338\n",
      "Epoch 47/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 7.2281 - mae: 7.2281\n",
      "Epoch 48/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 7.2225 - mae: 7.2225\n",
      "Epoch 49/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 7.2169 - mae: 7.2169\n",
      "Epoch 50/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 7.2113 - mae: 7.2113\n",
      "Epoch 51/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 7.2056 - mae: 7.2056\n",
      "Epoch 52/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 7.2000 - mae: 7.2000\n",
      "Epoch 53/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 7.1944 - mae: 7.1944\n",
      "Epoch 54/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 7.1888 - mae: 7.1888\n",
      "Epoch 55/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 7.1831 - mae: 7.1831\n",
      "Epoch 56/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 7.1775 - mae: 7.1775\n",
      "Epoch 57/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 7.1719 - mae: 7.1719\n",
      "Epoch 58/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - loss: 7.1663 - mae: 7.1663\n",
      "Epoch 59/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 7.1606 - mae: 7.1606\n",
      "Epoch 60/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 7.1550 - mae: 7.1550\n",
      "Epoch 61/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 7.1494 - mae: 7.1494\n",
      "Epoch 62/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 7.1438 - mae: 7.1438\n",
      "Epoch 63/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 7.1381 - mae: 7.1381\n",
      "Epoch 64/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 7.1325 - mae: 7.1325\n",
      "Epoch 65/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 7.1269 - mae: 7.1269\n",
      "Epoch 66/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 7.1213 - mae: 7.1213\n",
      "Epoch 67/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 7.1156 - mae: 7.1156\n",
      "Epoch 68/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 7.1100 - mae: 7.1100\n",
      "Epoch 69/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 7.1044 - mae: 7.1044\n",
      "Epoch 70/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 7.0988 - mae: 7.0988\n",
      "Epoch 71/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 7.0931 - mae: 7.0931\n",
      "Epoch 72/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 7.0875 - mae: 7.0875\n",
      "Epoch 73/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 7.0819 - mae: 7.0819\n",
      "Epoch 74/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 7.0763 - mae: 7.0763\n",
      "Epoch 75/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 7.0706 - mae: 7.0706\n",
      "Epoch 76/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 7.0650 - mae: 7.0650\n",
      "Epoch 77/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 7.0594 - mae: 7.0594\n",
      "Epoch 78/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 7.0538 - mae: 7.0538\n",
      "Epoch 79/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 7.0481 - mae: 7.0481\n",
      "Epoch 80/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 7.0425 - mae: 7.0425\n",
      "Epoch 81/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 7.0369 - mae: 7.0369\n",
      "Epoch 82/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 7.0313 - mae: 7.0313\n",
      "Epoch 83/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 7.0256 - mae: 7.0256\n",
      "Epoch 84/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 7.0200 - mae: 7.0200\n",
      "Epoch 85/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 7.0144 - mae: 7.0144\n",
      "Epoch 86/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 7.0087 - mae: 7.0087\n",
      "Epoch 87/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 7.0031 - mae: 7.0031\n",
      "Epoch 88/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 6.9975 - mae: 6.9975\n",
      "Epoch 89/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 6.9919 - mae: 6.9919\n",
      "Epoch 90/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 6.9863 - mae: 6.9863\n",
      "Epoch 91/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 6.9806 - mae: 6.9806\n",
      "Epoch 92/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 6.9750 - mae: 6.9750\n",
      "Epoch 93/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 6.9694 - mae: 6.9694\n",
      "Epoch 94/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 6.9638 - mae: 6.9638\n",
      "Epoch 95/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 6.9581 - mae: 6.9581\n",
      "Epoch 96/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 6.9525 - mae: 6.9525\n",
      "Epoch 97/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 6.9469 - mae: 6.9469\n",
      "Epoch 98/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 6.9413 - mae: 6.9413\n",
      "Epoch 99/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 6.9356 - mae: 6.9356\n",
      "Epoch 100/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 6.9300 - mae: 6.9300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x29dd08fdd60>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's rebuild our model\n",
    "\n",
    "# 1. Create the model\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "              optimizer=tf.keras.optimizers.SGD(),\n",
    "              metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model (this time we'll train for longer)\n",
    "# model.fit(X, y, epochs=100)\n",
    "# model.fit(X, y, epochs=100)\n",
    "model.fit(tf.expand_dims(X, axis=-1), y, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remind ourselves of the data\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[30.28471]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see if our model's prediction has improved...\n",
    "# model.predict([17.0])\n",
    "y_pred = model.predict(np.array([17.0]))\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 11.1761 - mae: 11.1761\n",
      "Epoch 2/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 10.3927 - mae: 10.3927\n",
      "Epoch 3/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 9.6052 - mae: 9.6052\n",
      "Epoch 4/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 8.8109 - mae: 8.8109\n",
      "Epoch 5/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 8.0080 - mae: 8.0080\n",
      "Epoch 6/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 7.1940 - mae: 7.1940\n",
      "Epoch 7/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 6.9986 - mae: 6.9986\n",
      "Epoch 8/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 7.4316 - mae: 7.4316\n",
      "Epoch 9/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 7.7127 - mae: 7.7127\n",
      "Epoch 10/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 7.8735 - mae: 7.8735\n",
      "Epoch 11/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 7.7854 - mae: 7.7854\n",
      "Epoch 12/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 7.5217 - mae: 7.5217\n",
      "Epoch 13/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 7.2368 - mae: 7.2368\n",
      "Epoch 14/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 6.9597 - mae: 6.9597\n",
      "Epoch 15/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 6.6633 - mae: 6.6633\n",
      "Epoch 16/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 6.4026 - mae: 6.4026\n",
      "Epoch 17/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 6.3474 - mae: 6.3474\n",
      "Epoch 18/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 6.3203 - mae: 6.3203\n",
      "Epoch 19/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 6.3927 - mae: 6.3927\n",
      "Epoch 20/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 6.3587 - mae: 6.3587\n",
      "Epoch 21/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 6.2324 - mae: 6.2324\n",
      "Epoch 22/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 6.0241 - mae: 6.0241\n",
      "Epoch 23/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 5.8811 - mae: 5.8811\n",
      "Epoch 24/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 5.7828 - mae: 5.7828\n",
      "Epoch 25/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 5.6818 - mae: 5.6818\n",
      "Epoch 26/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 5.6906 - mae: 5.6906\n",
      "Epoch 27/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 5.6694 - mae: 5.6694\n",
      "Epoch 28/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 5.5994 - mae: 5.5994\n",
      "Epoch 29/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 5.4849 - mae: 5.4849\n",
      "Epoch 30/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 5.3298 - mae: 5.3298\n",
      "Epoch 31/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 5.1375 - mae: 5.1375\n",
      "Epoch 32/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 5.0104 - mae: 5.0104\n",
      "Epoch 33/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 4.9147 - mae: 4.9147\n",
      "Epoch 34/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 4.8124 - mae: 4.8124\n",
      "Epoch 35/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 4.7893 - mae: 4.7893\n",
      "Epoch 36/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 4.6757 - mae: 4.6757\n",
      "Epoch 37/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 4.4501 - mae: 4.4501\n",
      "Epoch 38/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 4.2944 - mae: 4.2944\n",
      "Epoch 39/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 4.1392 - mae: 4.1392\n",
      "Epoch 40/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 4.1046 - mae: 4.1046\n",
      "Epoch 41/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 4.0289 - mae: 4.0289\n",
      "Epoch 42/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 3.8949 - mae: 3.8949\n",
      "Epoch 43/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 3.7058 - mae: 3.7058\n",
      "Epoch 44/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 3.4651 - mae: 3.4651\n",
      "Epoch 45/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 3.2039 - mae: 3.2039\n",
      "Epoch 46/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 3.0413 - mae: 3.0413\n",
      "Epoch 47/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 2.9209 - mae: 2.9209\n",
      "Epoch 48/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 2.7318 - mae: 2.7318\n",
      "Epoch 49/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 2.4634 - mae: 2.4634\n",
      "Epoch 50/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 2.2426 - mae: 2.2426\n",
      "Epoch 51/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 2.1198 - mae: 2.1198\n",
      "Epoch 52/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 1.9307 - mae: 1.9307\n",
      "Epoch 53/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 1.6697 - mae: 1.6697\n",
      "Epoch 54/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 1.3408 - mae: 1.3408\n",
      "Epoch 55/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 1.1973 - mae: 1.1973\n",
      "Epoch 56/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 1.0058 - mae: 1.0058\n",
      "Epoch 57/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.6365 - mae: 0.6365\n",
      "Epoch 58/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.4578 - mae: 0.4578\n",
      "Epoch 59/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.3041 - mae: 0.3041\n",
      "Epoch 60/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.2814 - mae: 0.2814\n",
      "Epoch 61/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.5052 - mae: 0.5052\n",
      "Epoch 62/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.5868 - mae: 0.5868\n",
      "Epoch 63/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.7775 - mae: 0.7775\n",
      "Epoch 64/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.7578 - mae: 0.7578\n",
      "Epoch 65/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.8054 - mae: 0.8054\n",
      "Epoch 66/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.8900 - mae: 0.8900\n",
      "Epoch 67/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.7456 - mae: 0.7456\n",
      "Epoch 68/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.6051 - mae: 0.6051\n",
      "Epoch 69/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.5660 - mae: 0.5660\n",
      "Epoch 70/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3523 - mae: 0.3523\n",
      "Epoch 71/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3843 - mae: 0.3843\n",
      "Epoch 72/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.2997 - mae: 0.2997\n",
      "Epoch 73/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.1345 - mae: 0.1345\n",
      "Epoch 74/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.2711 - mae: 0.2711\n",
      "Epoch 75/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2924 - mae: 0.2924\n",
      "Epoch 76/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3114 - mae: 0.3114\n",
      "Epoch 77/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.3369 - mae: 0.3369\n",
      "Epoch 78/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2902 - mae: 0.2902\n",
      "Epoch 79/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.2743 - mae: 0.2743\n",
      "Epoch 80/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.1580 - mae: 0.1580\n",
      "Epoch 81/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.2429 - mae: 0.2429\n",
      "Epoch 82/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.1448 - mae: 0.1448\n",
      "Epoch 83/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.2191 - mae: 0.2191\n",
      "Epoch 84/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.2181 - mae: 0.2181\n",
      "Epoch 85/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.2417 - mae: 0.2417\n",
      "Epoch 86/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.2323 - mae: 0.2323\n",
      "Epoch 87/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0977 - mae: 0.0977\n",
      "Epoch 88/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0829 - mae: 0.0829\n",
      "Epoch 89/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.2116 - mae: 0.2116\n",
      "Epoch 90/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.1852 - mae: 0.1852\n",
      "Epoch 91/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.2836 - mae: 0.2836\n",
      "Epoch 92/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.3550 - mae: 0.3550\n",
      "Epoch 93/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.2750 - mae: 0.2750\n",
      "Epoch 94/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0982 - mae: 0.0982\n",
      "Epoch 95/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0817 - mae: 0.0817\n",
      "Epoch 96/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.2051 - mae: 0.2051\n",
      "Epoch 97/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.1835 - mae: 0.1835\n",
      "Epoch 98/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.2577 - mae: 0.2577\n",
      "Epoch 99/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.3186 - mae: 0.3186\n",
      "Epoch 100/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.2283 - mae: 0.2283\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x29dd1c65820>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see if we can make another to improve our model\n",
    "\n",
    "# 1. Create the model (this time with an extra hidden layer with 100 hidden units)\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "  tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "  tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "  tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=\"mae\",\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "              # optimizer=tf.keras.optimizers.Adam(lr=0.01),\n",
    "              metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "# model.fit(X, y, epochs=100) \n",
    "model.fit(tf.expand_dims(X, axis=-1), y, epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[26.764715]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(np.array([17.0]))\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
